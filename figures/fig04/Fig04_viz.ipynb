{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bbe3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "from pygam import GAM, s\n",
    "from scipy.ndimage import convolve\n",
    "import collections\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import anndata as ad\n",
    "from typing import Optional\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b87a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e83184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_distances(adata):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(adata.obs.closest_cyst_distance.values.reshape(-1,1))\n",
    "    adata.obs.closest_cyst_distance = scaler.transform(adata.obs.closest_cyst_distance.values.reshape(-1,1))\n",
    "\n",
    "def normalize(adata):\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd6b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_pkd_1 = sc.read_h5ad(\"/exports/humgen/cnovellarausell/SevtapSpatial/pkd_1_visium_with_distances_and_areas.h5ad\")\n",
    "scale_distances(adata_pkd_1)\n",
    "normalize(adata_pkd_1)\n",
    "adata_pkd_2 = sc.read_h5ad(\"/exports/humgen/cnovellarausell/SevtapSpatial/pkd_2_visium_with_distances_and_areas.h5ad\")\n",
    "scale_distances(adata_pkd_2)\n",
    "normalize(adata_pkd_2)\n",
    "adata_pkd_3 = sc.read_h5ad(\"/exports/humgen/cnovellarausell/SevtapSpatial/pkd_3_visium_with_distances_and_areas.h5ad\")\n",
    "scale_distances(adata_pkd_3)\n",
    "normalize(adata_pkd_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = [adata_pkd_1, adata_pkd_2, adata_pkd_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adatas[0].concatenate(\n",
    "    adatas[1:3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91143642",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.closest_cyst_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[np.isfinite(adata.obs.closest_cyst_distance.values)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b87b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the base directory where the files are stored\n",
    "base_dir = '/exports/humgen/cnovellarausell/SevtapSpatial/'\n",
    "\n",
    "# Define the different PKD versions you are interested in\n",
    "pkds = ['pkd_1', 'pkd_2', 'pkd_3']\n",
    "\n",
    "# Create dictionaries to store the data for models, predictions, and test sets\n",
    "models_dict = {}\n",
    "y_test_dict_all = {}\n",
    "x_test_dict_all = {}\n",
    "\n",
    "# Loop over each PKD version to load the respective files\n",
    "for pkd in pkds:\n",
    "    # Load the trained models\n",
    "    model_path = f\"{base_dir}Trained_models_max_distance_val_end_{pkd}_scaled.pkl\"\n",
    "    with open(model_path, 'rb') as handle:\n",
    "        models_dict[pkd] = pickle.load(handle)\n",
    "\n",
    "    # Load the predictions\n",
    "    predictions_path = f\"{base_dir}Trained_mdodels_predictions_max_distance_val_end_{pkd}_scaled.pkl\"\n",
    "    with open(predictions_path, 'rb') as handle:\n",
    "        y_test_dict_all[pkd] = pickle.load(handle)\n",
    "\n",
    "    # Load the X test data\n",
    "    x_test_path = f\"{base_dir}Trained_mdodels_x_test_max_distance_val_end_{pkd}_scaled.pkl\"\n",
    "    with open(x_test_path, 'rb') as handle:\n",
    "        x_test_dict_all[pkd] = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_genes(y_test_dict, adata, n_top=100):\n",
    "    y_test_df = pd.DataFrame.from_dict(y_test_dict)\n",
    "    trends = sc.AnnData(y_test_df.T)  # Transpose to make genes as observations\n",
    "    trends.obs_names = y_test_df.columns\n",
    "    cols = [\"means\", \"dispersions\"]\n",
    "    trends.obs = trends.obs.merge(\n",
    "        right=adata.var[cols], how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "\n",
    "    first_state = trends.X[:, 0]\n",
    "    last_state = trends.X[:, -1]\n",
    "    abs_change = np.abs(first_state - last_state)\n",
    "    change = first_state - last_state\n",
    "    # Add this as a column in the .obs DataFrame\n",
    "    trends.obs['abs_change'] = abs_change\n",
    "    trends.obs['change'] = change\n",
    "    # compute change at every point and store in a layer\n",
    "    trends.layers['point_delta'] = np.diff(trends.X, axis=1, prepend=trends.X[:, 0:1])\n",
    "    trends.layers['point_abs_delta'] = np.abs(np.diff(trends.X, axis=1, prepend=trends.X[:, 0:1]))\n",
    "    trends.obs['first20_abs_delta'] = np.sum(trends.layers['point_abs_delta'][:, :20], axis=1)\n",
    "    trends.obs['first20_delta'] = np.sum(trends.layers['point_delta'][:, :20], axis=1)\n",
    "    trends.obs['first10_abs_delta'] = np.sum(trends.layers['point_abs_delta'][:, :10], axis=1)\n",
    "    trends.obs['last190_abs_delta'] = np.sum(trends.layers['point_abs_delta'][:, 10:], axis=1)\n",
    "    trends.obs['first10_delta'] = np.sum(trends.layers['point_delta'][:, :10], axis=1)\n",
    "    trends.obs['last190_delta'] = np.sum(trends.layers['point_delta'][:, 10:], axis=1)\n",
    "    trends.obs['last190_mean'] = np.mean(trends.X[:, 10:], axis=1)\n",
    "    trends.obs['close_peak'] = trends.obs['first10_delta'] + trends.obs['last190_abs_delta'] #-|Delta1| \n",
    "\n",
    "\n",
    "    \n",
    "    # Sort and get top genes\n",
    "    sorted_genes = trends.obs.sort_values('first10_delta', ascending=True).head(n_top).sort_values('last190_abs_delta', ascending=True, key=abs).head(n_top).index\n",
    "    # specific  trends.obs.sort_values(['first10_abs_delta'], ascending=[False]).head(100).sort_values(\"means\", ascending=True).head(n_top).index\n",
    "    # stable trends.obs.sort_values('first10_delta', ascending=True).head(n_top).sort_values('last190_abs_delta', ascending=True, key=abs).head(n_top).index\n",
    "    return sorted_genes\n",
    "\n",
    "\n",
    "\n",
    "def plot_genes(dataset_name, gene_set, y_test_dict, adata):\n",
    "    selected_genes = sorted(list(gene_set))  # sorted list of unique genes\n",
    "    genes_per_group = 20  # Number of genes per plot group\n",
    "    n_cols = 3  # Fixed number of columns\n",
    "\n",
    "    if len(selected_genes) == 0:\n",
    "        print(f\"No unique genes to plot for {dataset_name}.\")\n",
    "        return\n",
    "\n",
    "    # Define a color palette for the plots\n",
    "    colors = sns.color_palette('tab10', n_colors=3)  # 'husl' is vibrant; adjust the palette as needed\n",
    "\n",
    "    # Calculate the number of rows needed for the subplots\n",
    "    n_rows = (len(selected_genes) + n_cols - 1) // n_cols  # Ceiling division for rows\n",
    "\n",
    "    # Create the figure with the calculated number of rows and columns\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    if n_rows * n_cols > 1:\n",
    "        axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "    else:\n",
    "        axes = [axes]  # Ensure axes is iterable\n",
    "\n",
    "    for i, gene in enumerate(selected_genes):\n",
    "        ax = axes[i]  # Get the current axis for the gene\n",
    "\n",
    "        # Plot predictions for the specific dataset\n",
    "        if gene in y_test_dict[dataset_name]:\n",
    "            x_pred = np.linspace(0, 1, len(y_test_dict[dataset_name][gene]))  # Assuming evenly spaced predictions\n",
    "            sns.lineplot(x=x_pred, y=y_test_dict[dataset_name][gene], ax=ax, label=f'{dataset_name} Predicted', color=colors[int(str(dataset_name).split('_')[1]) - 1])\n",
    "\n",
    "        # # Actual gene expression data plot\n",
    "        # if gene in adata.var_names:\n",
    "        #     gene_expression = adata[:, gene].X.flatten()\n",
    "        #     distances = adata[:, gene].obs['closest_cyst_distance'].values\n",
    "        #     sns.scatterplot(x=distances, y=gene_expression, ax=ax, color='red', s=10, label='Actual', alpha=0.6)\n",
    "\n",
    "        sns.despine()\n",
    "        ax.set_title(gene)\n",
    "        ax.set_ylabel('Expression')\n",
    "        ax.set_xlabel('Distance to cyst')\n",
    "        ax.legend()\n",
    "\n",
    "    # Turn off unused axes\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')  # Turn off any remaining axes not used\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_test_dict_all contains all prediction dictionaries for pkd_1, pkd_2, pkd_3\n",
    "top_genes_pkd1 = get_top_genes(y_test_dict_all['pkd_1'], adata)\n",
    "top_genes_pkd2 = get_top_genes(y_test_dict_all['pkd_2'], adata)\n",
    "top_genes_pkd3 = get_top_genes(y_test_dict_all['pkd_3'], adata)\n",
    "\n",
    "# Convert to sets if not already\n",
    "set_genes_pkd1 = set(top_genes_pkd1)\n",
    "set_genes_pkd2 = set(top_genes_pkd2)\n",
    "set_genes_pkd3 = set(top_genes_pkd3)\n",
    "\n",
    "# Find the intersection of top genes across all datasets\n",
    "common_genes = set_genes_pkd1.intersection(set_genes_pkd2, set_genes_pkd3)\n",
    "\n",
    "# Find genes unique to pkd_1 (present in pkd_1 but not in pkd_2 and pkd_3)\n",
    "unique_genes_pkd1 = set_genes_pkd1 - (set_genes_pkd2.union(set_genes_pkd3))\n",
    "\n",
    "# Find genes unique to pkd_2 (present in pkd_2 but not in pkd_1 and pkd_3)\n",
    "unique_genes_pkd2 = set_genes_pkd2 - (set_genes_pkd1.union(set_genes_pkd3))\n",
    "\n",
    "# Find genes unique to pkd_3 (present in pkd_3 but not in pkd_1 and pkd_2)\n",
    "unique_genes_pkd3 = set_genes_pkd3 - (set_genes_pkd1.union(set_genes_pkd2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5c8d7-d4b7-4414-933d-a91f8cdd4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd7baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import binned_statistic\n",
    "\n",
    "selected_genes = sorted(list(common_genes))  # sorted list of common genes\n",
    "genes_per_group = 45  # Number of genes per plot group\n",
    "\n",
    "for group_index, group_start in enumerate(range(0, len(selected_genes), genes_per_group)):\n",
    "    current_group_genes = selected_genes[group_start:group_start + genes_per_group]\n",
    "    \n",
    "    fig, axes = plt.subplots(9, 5, figsize=(6,6))  # Increased figsize for better visibility\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, gene in enumerate(current_group_genes):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        for pkd, color in zip(['pkd_1', 'pkd_2', 'pkd_3'], ['blue', 'green', 'purple']):\n",
    "            # Plot predictions\n",
    "            x_pred = np.linspace(0, 1, len(y_test_dict_all[pkd][gene]))\n",
    "            y_pred = y_test_dict_all[pkd][gene]\n",
    "    \n",
    "            ax.plot(x_pred, y_pred,  label=f'{pkd} Predicted', linewidth=1.5)\n",
    "            \n",
    "            # Plot actual data\n",
    "            # gene_expression = adata[adata.obs.library_id==pkd][:, gene].X.A.reshape(-1,)\n",
    "            # distances = adata[adata.obs.library_id==pkd][:, gene].obs['closest_cyst_distance'].values\n",
    "            # Bin the actual data\n",
    "            # bins = np.linspace(0, 1, 200)\n",
    "            # binned_expression, _, _ = binned_statistic(distances, gene_expression, statistic='median', bins=bins)\n",
    "            # bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "            \n",
    "            # ax.scatter(bin_centers, binned_expression,  s=1, alpha=0.1, label=f'{pkd} Actual (binned)')\n",
    "        \n",
    "        plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=None)\n",
    "        sns.despine()\n",
    "        # Turn off x-axis labels and ticks for all but the last row\n",
    "        if (i // 5) != 8:  # Only the last row index (i // 5 == 8 for 9 rows and zero-index)\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_xlabel('')\n",
    "            ax.xaxis.set_ticks_position('none')\n",
    "        ax.set_title(gene, fontdict={'fontsize': 10}, y=0.7)\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    handles, labels = axes[i].get_legend_handles_labels()\n",
    "\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.02), ncol=3, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63926ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import decoupler as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a69bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes = sorted(list(common_genes))  # sorted list of common genes\n",
    "\n",
    "signature = pd.DataFrame(selected_genes, columns=[\"target\"])\n",
    "signature[\"source\"] = 'Cystic genes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e86ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.run_ora(\n",
    "    mat=adata,\n",
    "    net=signature,\n",
    "    source='source',\n",
    "    target='target',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9f802-50f1-4c72-8c9a-845ea650910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['ora_estimate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40925652",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = dc.get_acts(adata, obsm_key='ora_estimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b62efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts.obsm['spatial'] = adata.obsm['spatial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['spatial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da672a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "tab10_colors = sns.color_palette(\"tab10\", 10)  # tab10 has 10 colors\n",
    "def create_sequential_colormap(color):\n",
    "    \"\"\"Creates a sequential colormap from a given RGB color.\"\"\"\n",
    "    # Create a color map that interpolates between white and the given color\n",
    "    colors = [(1, 1, 1), color]  # from white to the color\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_seq_cmap\", colors)\n",
    "    return cmap\n",
    "\n",
    "# Create a dictionary to hold the colormaps\n",
    "sequential_colormaps = {f'tab10_seq_{i}': create_sequential_colormap(color) for i, color in enumerate(tab10_colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(\n",
    "    acts[acts.obs.library_id=='pkd_1'],\n",
    "    color=['Cystic genes'],\n",
    "    cmap=sequential_colormaps['tab10_seq_0'],\n",
    "    spot_size=200,\n",
    "    frameon=False,\n",
    "    show=False\n",
    ")\n",
    "#plt.savefig('/exports/archive/hg-groep-peters/Spatial_Transcriptomics_Snowball_Sevtap/Figures_without_unknown_cluster/Gene_trends_to_cyst/Scaled_distances_together/Matching_trends_ORA_plot_pkd_1.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7038c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(\n",
    "    acts[acts.obs.library_id=='pkd_2'],\n",
    "    color=['Cystic genes'],\n",
    "    cmap=sequential_colormaps['tab10_seq_1'],\n",
    "    spot_size=200,\n",
    "    frameon=False,\n",
    "    show=False,\n",
    ")\n",
    "#plt.savefig('/exports/archive/hg-groep-peters/Spatial_Transcriptomics_Snowball_Sevtap/Figures_without_unknown_cluster/Gene_trends_to_cyst/Scaled_distances_together/Matching_trends_ORA_plot_pkd_2.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(\n",
    "    acts[acts.obs.library_id=='pkd_3'],\n",
    "    color=['Cystic genes'],\n",
    "    cmap=sequential_colormaps['tab10_seq_2'],\n",
    "    spot_size=200,\n",
    "    frameon=False,\n",
    "    show=False\n",
    ")\n",
    "#plt.savefig('/exports/archive/hg-groep-peters/Spatial_Transcriptomics_Snowball_Sevtap/Figures_without_unknown_cluster/Gene_trends_to_cyst/Scaled_distances_together/Matching_trends_ORA_plot_pkd_3.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46a9b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts[acts.obs.library_id=='pkd_3'].obs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkd_3_acts = acts[acts.obs.library_id=='pkd_3'].copy()\n",
    "pkd_2_acts = acts[acts.obs.library_id=='pkd_2'].copy()\n",
    "pkd_1_acts = acts[acts.obs.library_id=='pkd_1'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkd_3_acts.obs_names = pkd_3_acts.obs_names.str.split('-').str[0]\n",
    "pkd_2_acts.obs_names = pkd_2_acts.obs_names.str.split('-').str[0]\n",
    "pkd_1_acts.obs_names = pkd_1_acts.obs_names.str.split('-').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9246d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkd_1_segmented_data = pd.read_csv(\"/exports/archive/hg-groep-peters/Spatial_Transcriptomics_Snowball_Sevtap/pkd_1_tangram_segmented_nuclei_data_withPKD.csv\")\n",
    "pkd_2_segmented_data = pd.read_csv(\"/exports/archive/hg-groep-peters/Spatial_Transcriptomics_Snowball_Sevtap/pkd_2_tangram_segmented_nuclei_data_withPKD.csv\")\n",
    "pkd_3_segmented_data = pd.read_csv(\"/exports/archive/hg-groep-peters/Spatial_Transcriptomics_Snowball_Sevtap/pkd_3_tangram_segmented_nuclei_data_withPKD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf3d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkd_1_segmented_data.centroids = pkd_1_segmented_data.centroids.str.split('-').str[0]\n",
    "pkd_2_segmented_data.centroids = pkd_2_segmented_data.centroids.str.split('-').str[0]\n",
    "pkd_3_segmented_data.centroids = pkd_3_segmented_data.centroids.str.split('-').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27fb7d-9204-48ae-8968-df383c8f1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkd_1_segmented_data['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffad4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res = {\n",
    "    'Macro': ['Lyc6 low Macrophages', 'Lyc6 high Macrophages','Spp1+ Resident Macrophages ', 'Mrc1+ Resident Macrophages'],\n",
    "    'NK': ['Gzma+ NK', 'Gzma low NK', 'NKT1', 'Gzma+ NK'],\n",
    "    'B lymph': ['B1 B lymph', 'B1 B lymph', 'T3/Follicular B lymph', 'T1 B lymph', 'Memory B lymph'],\n",
    "    'T lymph': ['CD4+ Th17', 'CD4+ T regs', 'Gzma+ CD8+ T lymph', 'CD4+ T lymph']}\n",
    "low_res_rev = {vs: k for k, v in low_res.items() for vs in v}\n",
    "pkd_1_segmented_data['cluster'] = pkd_1_segmented_data['cluster'].replace(low_res_rev)\n",
    "pkd_2_segmented_data['cluster'] = pkd_2_segmented_data['cluster'].replace(low_res_rev)\n",
    "pkd_3_segmented_data['cluster'] = pkd_3_segmented_data['cluster'].replace(low_res_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa5b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_anndata_and_compute_correlations(activities, segmented_data, adata_name):\n",
    "    # Load the AnnData object\n",
    "    adata = activities.copy()\n",
    "\n",
    "    # Load the DataFrame\n",
    "    df = segmented_data.copy()\n",
    "\n",
    "    # Compute the percentage of each cell type per unique centroid\n",
    "    grouped = df.groupby(['centroids', 'cluster']).size().reset_index(name='counts')\n",
    "    total_counts = grouped.groupby('centroids')['counts'].transform('sum')\n",
    "    grouped['percentage'] = grouped['counts'] / total_counts * 100\n",
    "    percentage_df = grouped.pivot(index='centroids', columns='cluster', values='percentage').fillna(0)\n",
    "\n",
    "    # Align the percentage dataframe with the AnnData object\n",
    "    adata_centroids = adata.obs_names.to_list()\n",
    "    centroid_percentage_df = percentage_df.reindex(adata_centroids).fillna(0)\n",
    "    \n",
    "    # Add the percentages to the AnnData object's obs attribute\n",
    "    for column in centroid_percentage_df.columns:\n",
    "        adata.obs[f'percentage_{column}'] = centroid_percentage_df[column].values\n",
    "\n",
    "    # Step 3: Extract the feature values from .X\n",
    "    feature_values = adata.X[:, 0].flatten()  # Assuming there's only one feature and it's in the first column\n",
    "\n",
    "    # Extract the percentage columns\n",
    "    percentage_columns = [col for col in adata.obs.columns if col.startswith('percentage_')]\n",
    "    percentage_df = adata.obs[percentage_columns]\n",
    "\n",
    "    # Calculate the correlation between the feature and each cell type percentage\n",
    "    correlation_results = {\n",
    "        'cell_type': [],\n",
    "        'correlation': [],\n",
    "        'p_value': [],\n",
    "        'dataset': []\n",
    "    }\n",
    "\n",
    "    for col in percentage_columns:\n",
    "        correlation, p_value = pearsonr(feature_values, adata.obs[col].values)\n",
    "        correlation_results['cell_type'].append(col.split('_')[1])\n",
    "        correlation_results['correlation'].append(correlation)\n",
    "        correlation_results['p_value'].append(p_value)\n",
    "        correlation_results['dataset'].append(adata_name)\n",
    "    \n",
    "    # Return both the modified AnnData object and the correlation results as a DataFrame\n",
    "    return adata, pd.DataFrame(correlation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7168fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Aggregate correlation results from all datasets\n",
    "all_correlations = pd.DataFrame()\n",
    "activities_list = [pkd_1_acts, pkd_2_acts, pkd_3_acts]\n",
    "segmented_data_list = [pkd_1_segmented_data, pkd_2_segmented_data, pkd_3_segmented_data]\n",
    "segmented_data_list_with_new_annot = []\n",
    "for activity, segmented_data, adata_name in zip(activities_list, segmented_data_list, ['pkd_1', 'pkd_2', 'pkd_3']):\n",
    "    adata, correlation_df = process_anndata_and_compute_correlations(activity, segmented_data, adata_name)\n",
    "    print(correlation_df)\n",
    "    segmented_data_list_with_new_annot.append(adata)\n",
    "    all_correlations = pd.concat([all_correlations, correlation_df], ignore_index=True)\n",
    "\n",
    "# Apply Benjamini-Hochberg correction for multiple testing\n",
    "p_values = all_correlations['p_value'].values\n",
    "reject, pvals_corrected, _, _ = multipletests(p_values, method='fdr_bh', alpha=0.01)\n",
    "\n",
    "# Add the corrected p-values to the DataFrame\n",
    "all_correlations['p_value_corrected'] = pvals_corrected\n",
    "all_correlations['significant'] = reject\n",
    "\n",
    "\n",
    "# Separate significant and non-significant correlations\n",
    "significant_correlations = all_correlations[all_correlations['significant']]\n",
    "non_significant_correlations = all_correlations[~all_correlations['significant']]\n",
    "\n",
    "\n",
    "# Plot significant correlations with solid bars\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(x='cell_type', y='correlation', hue='dataset', data=all_correlations)\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Cell Type')\n",
    "plt.ylabel('Pearson Correlation Coefficient')\n",
    "plt.legend([], [], frameon=False)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('/exports/archive/hg-groep-peters/Spatial_Transcriptomics_Snowball_Sevtap/Figures_without_unknown_cluster/Gene_trends_to_cyst/Cystic_gene_signature_cell_type_all_correlations_withPKD.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "for activity, segmented_data, adata_name in zip(activities_list, segmented_data_list, ['pkd_1', 'pkd_2', 'pkd_3']):    \n",
    "    correlation_df = process_anndata_and_compute_correlations(activity, segmented_data, adata_name)\n",
    "    all_correlations = pd.concat([all_correlations, correlation_df], ignore_index=True)\n",
    "\n",
    "    # Load the AnnData object and DataFrame again to get the full data\n",
    "    adata = activity.copy()\n",
    "    df = segmented_data.copy()\n",
    "    \n",
    "    # Add dataset name to DataFrame\n",
    "    df['dataset'] = adata_name\n",
    "    \n",
    "    # Merge percentages into the DataFrame\n",
    "    grouped = df.groupby(['centroids', 'cluster']).size().reset_index(name='counts')\n",
    "    total_counts = grouped.groupby('centroids')['counts'].transform('sum')\n",
    "    grouped['percentage'] = grouped['counts'] / total_counts * 100\n",
    "    percentage_df = grouped.pivot(index='centroids', columns='cluster', values='percentage').fillna(0)\n",
    "    centroid_percentage_df = percentage_df.reindex(adata.obs_names.to_list()).fillna(0)\n",
    "    for column in centroid_percentage_df.columns:\n",
    "        adata.obs[f'percentage_{column}'] = centroid_percentage_df[column].values\n",
    "    \n",
    "    # Extract PT-Inj data\n",
    "    pt_inj_data = pd.DataFrame({\n",
    "        'feature_value': adata.X[:, 0].flatten(),\n",
    "        'percentage_Macro': adata.obs['percentage_Macro'],\n",
    "        'dataset': adata_name\n",
    "    })\n",
    "    all_data.append(pt_inj_data)\n",
    "\n",
    "# Concatenate all PT-Inj data\n",
    "all_pt_inj_data = pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee73971",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkd_1_with_distances = sc.read_h5ad(\"/exports/humgen/cnovellarausell/SevtapSpatial/pkd_1_segment_with_distances_withPKD.h5ad\")\n",
    "scale_distances(pkd_1_with_distances)\n",
    "pkd_2_with_distances = sc.read_h5ad(\"/exports/humgen/cnovellarausell/SevtapSpatial/pkd_2_segment_with_distances_withPKD.h5ad\")\n",
    "scale_distances(pkd_2_with_distances)\n",
    "pkd_3_with_distances = sc.read_h5ad(\"/exports/humgen/cnovellarausell/SevtapSpatial/pkd_3_segment_with_distances_withPKD.h5ad\")\n",
    "scale_distances(pkd_3_with_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae6941-f9e9-4e06-b2d8-b4a006f33468",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res = {\n",
    "    'Macro': ['Lyc6 low Macrophages', 'Lyc6 high Macrophages','Spp1+ Resident Macrophages ', 'Mrc1+ Resident Macrophages'],\n",
    "    'NK': ['Gzma+ NK', 'Gzma low NK', 'NKT1', 'Gzma+ NK'],\n",
    "    'B lymph': ['B1 B lymph', 'B1 B lymph', 'T3/Follicular B lymph', 'T1 B lymph', 'Memory B lymph'],\n",
    "    'T lymph': ['CD4+ Th17', 'CD4+ T regs', 'Gzma+ CD8+ T lymph', 'CD4+ T lymph']}\n",
    "low_res_rev = {vs: k for k, v in low_res.items() for vs in v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa6f13-e996-403b-ae8c-ffac4e966fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkd_1_with_distances.obs['cluster'] = pkd_1_with_distances.obs.cluster.replace(low_res_rev)\n",
    "pkd_2_with_distances.obs['cluster'] = pkd_2_with_distances.obs.cluster.replace(low_res_rev)\n",
    "pkd_3_with_distances.obs['cluster'] = pkd_3_with_distances.obs.cluster.replace(low_res_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkd_1_segmented_data = pd.read_csv(\"/exports/archive/hg-groep-peters/Spatial_Transcriptomics_Snowball_Sevtap/pkd_1_tangram_segmented_nuclei_data_withPKD.csv\")\n",
    "pkd_2_segmented_data = pd.read_csv(\"/exports/archive/hg-groep-peters/Spatial_Transcriptomics_Snowball_Sevtap/pkd_2_tangram_segmented_nuclei_data_withPKD.csv\")\n",
    "pkd_3_segmented_data = pd.read_csv(\"/exports/archive/hg-groep-peters/Spatial_Transcriptomics_Snowball_Sevtap/pkd_3_tangram_segmented_nuclei_data_withPKD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a57680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res = {\n",
    "    'Macro': ['Lyc6 low Macrophages', 'Lyc6 high Macrophages','Spp1+ Resident Macrophages ', 'Mrc1+ Resident Macrophages'],\n",
    "    'NK': ['Gzma+ NK', 'Gzma low NK', 'NKT1', 'Gzma+ NK'],\n",
    "    'B lymph': ['B1 B lymph', 'B1 B lymph', 'T3/Follicular B lymph', 'T1 B lymph', 'Memory B lymph'],\n",
    "    'T lymph': ['CD4+ Th17', 'CD4+ T regs', 'Gzma+ CD8+ T lymph', 'CD4+ T lymph']}\n",
    "low_res_rev = {vs: k for k, v in low_res.items() for vs in v}\n",
    "pkd_1_segmented_data['cluster'] = pkd_1_segmented_data['cluster'].replace(low_res_rev)\n",
    "pkd_2_segmented_data['cluster'] = pkd_2_segmented_data['cluster'].replace(low_res_rev)\n",
    "pkd_3_segmented_data['cluster'] = pkd_3_segmented_data['cluster'].replace(low_res_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890fdce9-b5b2-45d1-b27e-6a8c8ec20fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkd_1_cluster_distance_to_cyst = pkd_1_with_distances.obs.groupby('cluster')['closest_cyst_distance'].apply('median')\n",
    "pkd_2_cluster_distance_to_cyst = pkd_2_with_distances.obs.groupby('cluster')['closest_cyst_distance'].apply('median')\n",
    "pkd_3_cluster_distance_to_cyst = pkd_3_with_distances.obs.groupby('cluster')['closest_cyst_distance'].apply('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177c5e9-5dd6-45fe-846d-97303aefef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkd_1_cluster_abundance = pkd_1_with_distances.obs.cluster.value_counts(normalize=True)\n",
    "pkd_2_cluster_abundance = pkd_2_with_distances.obs.cluster.value_counts(normalize=True)\n",
    "pkd_3_cluster_abundance = pkd_3_with_distances.obs.cluster.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97601911-83fe-4295-a948-7f587f043b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames from each series\n",
    "pkd_1_df = pd.DataFrame(pkd_1_cluster_abundance).reset_index()\n",
    "pkd_1_df['dataset'] = 'pkd_1'\n",
    "\n",
    "pkd_2_df = pd.DataFrame(pkd_2_cluster_abundance).reset_index()\n",
    "pkd_2_df['dataset'] = 'pkd_2'\n",
    "\n",
    "pkd_3_df = pd.DataFrame(pkd_3_cluster_abundance).reset_index()\n",
    "pkd_3_df['dataset'] = 'pkd_3'\n",
    "\n",
    "# Rename 'index' column to 'cell_type'\n",
    "pkd_1_df.rename(columns={'index': 'cell_type', 'cluster': 'cell_type'}, inplace=True)\n",
    "pkd_2_df.rename(columns={'index': 'cell_type', 'cluster': 'cell_type'}, inplace=True)\n",
    "pkd_3_df.rename(columns={'index': 'cell_type', 'cluster': 'cell_type'}, inplace=True)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "all_cluster_abundances = pd.concat([pkd_1_df, pkd_2_df, pkd_3_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21da814-5883-4165-8cf1-189b9a3dd20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames from each series\n",
    "pkd_1_df = pd.DataFrame(pkd_1_cluster_distance_to_cyst).reset_index()\n",
    "pkd_1_df['dataset'] = 'pkd_1'\n",
    "\n",
    "pkd_2_df = pd.DataFrame(pkd_2_cluster_distance_to_cyst).reset_index()\n",
    "pkd_2_df['dataset'] = 'pkd_2'\n",
    "\n",
    "pkd_3_df = pd.DataFrame(pkd_3_cluster_distance_to_cyst).reset_index()\n",
    "pkd_3_df['dataset'] = 'pkd_3'\n",
    "\n",
    "# Rename 'index' column to 'cell_type'\n",
    "pkd_1_df.rename(columns={'cluster': 'cell_type'}, inplace=True)\n",
    "pkd_2_df.rename(columns={'cluster': 'cell_type'}, inplace=True)\n",
    "pkd_3_df.rename(columns={'cluster': 'cell_type'}, inplace=True)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "all_cluster_distances = pd.concat([pkd_1_df, pkd_2_df, pkd_3_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c87a2-23f0-407e-9e2e-23c7bc122e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes on 'cell_type' and 'dataset'\n",
    "merged_df = pd.merge(all_cluster_abundances, all_cluster_distances, on=[\"cell_type\", \"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a9848-c998-4776-bff7-8e8e8219909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average abundance and average closest_cyst_distance for each cell_type\n",
    "avg_df = merged_df.groupby('cell_type').agg(\n",
    "    avg_abundance=('proportion', 'mean'),\n",
    "    avg_distance=('closest_cyst_distance', 'mean')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e8789-9c4b-4231-9780-6e353c2db530",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_order = avg_df.sort_values('avg_distance').cell_type.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your AnnData objects are named pkd_1_with_distances, pkd_2_with_distances, pkd_3_with_distances\n",
    "adatas = [pkd_1_with_distances, pkd_2_with_distances, pkd_3_with_distances]\n",
    "dataset_names = ['pkd_1', 'pkd_2', 'pkd_3']\n",
    "\n",
    "# Define marker styles for each dataset\n",
    "marker_styles = ['o', 'o', 'o']  # circle, square, triangle\n",
    "\n",
    "avg_distances = []\n",
    "for adata, name in zip(adatas, dataset_names):\n",
    "    df = pd.DataFrame({\n",
    "        'closest_cyst_distance': adata.obs['closest_cyst_distance'],\n",
    "        'cluster': adata.obs['cluster']\n",
    "    })\n",
    "    avg_dist = df.groupby('cluster')['closest_cyst_distance'].mean().reset_index()\n",
    "    avg_dist['dataset'] = name\n",
    "    avg_distances.append(avg_dist)\n",
    "\n",
    "avg_distances = pd.concat(avg_distances, ignore_index=True)\n",
    "\n",
    "# Create a categorical type with the desired order\n",
    "avg_distances['cluster'] = pd.Categorical(avg_distances['cluster'], categories=cluster_order, ordered=True)\n",
    "\n",
    "# Sort the dataframe\n",
    "avg_distances = avg_distances.sort_values(['cluster', 'dataset'])\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Connect dots for each cell type\n",
    "for cell_type in cluster_order:\n",
    "    cell_data = avg_distances[avg_distances['cluster'] == cell_type]\n",
    "    plt.plot(cell_data['cluster'], cell_data['closest_cyst_distance'], 'k-', alpha=0.8, color='black')\n",
    "\n",
    "# Create scatter plot with different marker styles\n",
    "for i, dataset in enumerate(dataset_names):\n",
    "    data = avg_distances[avg_distances['dataset'] == dataset]\n",
    "    plt.scatter(data['cluster'], data['closest_cyst_distance'], \n",
    "                label=dataset, marker=marker_styles[i], s=100, \n",
    "                linewidths=1.5, edgecolors='black', \n",
    "                c=[sns.color_palette(\"deep\")[i]])\n",
    "\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sc_analysis]",
   "language": "python",
   "name": "conda-env-sc_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
